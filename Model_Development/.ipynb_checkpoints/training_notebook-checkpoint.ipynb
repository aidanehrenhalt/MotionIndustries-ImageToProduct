{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35251eb6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from PIL import Image\n",
    "\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40568d02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31b336f6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "IMG_H = 28\n",
    "IMG_W = 28\n",
    "IMG_C = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92d7f4c6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Transform to resize images\n",
    "motion_transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_H, IMG_W)),\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9fb76c07",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Custom Dataset class to read the data from the excel file and image directory\n",
    "class MotionDataset(Dataset):\n",
    "    def __init__(self, xlsx_file, image_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            xlsx_file (string): Path to the excel file with annotations.\n",
    "            image_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.data_info = pd.read_excel(xlsx_file)\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_info)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        img_name = os.path.join(self.image_dir,\n",
    "                                str(self.data_info.iloc[idx]['PrimaryImageFilename']))\n",
    "        image = Image.open(img_name).convert('RGB')\n",
    "\n",
    "        # 'PGC1' is the target label\n",
    "        label = self.data_info.iloc[idx]['PGC1']-1\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f350717e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "dataset = MotionDataset(xlsx_file='cleaned_product_list.xlsx', image_dir='/home/hice1/rlopez76/scratch/motion_dataset', transform=motion_transform)\n",
    "train_size = int(len(dataset) * 0.8)\n",
    "test_size = len(dataset) - train_size\n",
    "\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32) # need to look into other parameters\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)\n",
    "\n",
    "train_N = len(train_loader.dataset)\n",
    "test_N = len(test_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0fa73b69",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "N_CLASSES = 8\n",
    "KERNEL_SIZE = 3\n",
    "FLATTENED_IMG_SIZE = IMG_H * IMG_W * IMG_C\n",
    "\n",
    "model = nn.Sequential(\n",
    "        nn.Conv2d(in_channels=3, out_channels=25, kernel_size=3, stride=1, padding=1),\n",
    "        nn.BatchNorm2d(25),\n",
    "        nn.ReLU(),        \n",
    "        nn.MaxPool2d(2, stride = 2),\n",
    "        nn.Conv2d(in_channels=25, out_channels=50, kernel_size=3, stride=1, padding=1),\n",
    "        nn.BatchNorm2d(50),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.2),\n",
    "        nn.MaxPool2d(2, stride = 2),\n",
    "        nn.Conv2d(in_channels=50, out_channels=75, kernel_size=3, stride=1, padding=1),\n",
    "        nn.BatchNorm2d(75),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.2), \n",
    "        nn.MaxPool2d(2, stride = 2),\n",
    "        nn.Flatten(), \n",
    "        nn.Linear(675, 512),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.3),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(512, N_CLASSES)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2342f4c3",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "def save_checkpoint(model, optimizer, epoch, loss, save_path):\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': loss,\n",
    "    }, save_path)\n",
    "    \n",
    "def load_checkpoint(model, optimizer, load_path):\n",
    "    checkpoint = torch.load(load_path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    epoch = checkpoint['epoch']\n",
    "    loss = checkpoint['loss']\n",
    "    \n",
    "    return model, optimizer, epoch, loss\n",
    "\n",
    "def get_batch_accuracy(output, y, N):\n",
    "    pred = output.argmax(dim = 1, keepdim = True)\n",
    "    correct = pred.eq(y.view_as(pred)).sum().item()\n",
    "    acc = correct / N\n",
    "    return acc\n",
    "\n",
    "def train():\n",
    "    loss = 0\n",
    "    accuracy = 0\n",
    "\n",
    "    model.train()\n",
    "    for x, y in train_loader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "#         print(\"x shape\", x.shape)\n",
    "        \n",
    "#         firstx = x\n",
    "        \n",
    "#         layer = nn.Conv2d(in_channels=3, out_channels=25, kernel_size=3, stride=1, padding=1)\n",
    "#         out_tensor = layer(x)\n",
    "        \n",
    "#         layer = nn.BatchNorm2d(25)\n",
    "#         out_tensor = layer(out_tensor)\n",
    "        \n",
    "#         layer = nn.ReLU()        \n",
    "#         out_tensor = layer(out_tensor)\n",
    "                        \n",
    "#         layer = nn.MaxPool2d(2, stride = 2)\n",
    "#         out_tensor = layer(out_tensor)\n",
    "            \n",
    "#         layer = nn.Conv2d(in_channels=25, out_channels=50, kernel_size=3, stride=1, padding=1)\n",
    "#         out_tensor = layer(out_tensor)\n",
    "        \n",
    "#         layer = nn.BatchNorm2d(50)\n",
    "#         out_tensor = layer(out_tensor)\n",
    "            \n",
    "#         layer = nn.ReLU()    \n",
    "#         out_tensor = layer(out_tensor)\n",
    "        \n",
    "#         layer = nn.Dropout(0.2)\n",
    "#         out_tensor = layer(out_tensor)\n",
    "        \n",
    "#         layer = nn.MaxPool2d(2, stride = 2)\n",
    "#         out_tensor = layer(out_tensor)        \n",
    "        \n",
    "#         layer = nn.Conv2d(in_channels=50, out_channels=75, kernel_size=3, stride=1, padding=1)\n",
    "#         out_tensor = layer(out_tensor)\n",
    "        \n",
    "#         layer = nn.BatchNorm2d(75)\n",
    "#         out_tensor = layer(out_tensor)\n",
    "            \n",
    "#         layer = nn.ReLU()\n",
    "#         out_tensor = layer(out_tensor)\n",
    "            \n",
    "#         layer = nn.Dropout(0.2)    \n",
    "#         out_tensor = layer(out_tensor)\n",
    "                \n",
    "#         layer = nn.MaxPool2d(2, stride = 2)\n",
    "#         out_tensor = layer(out_tensor)\n",
    "        \n",
    "#         layer = nn.Flatten()        \n",
    "#         out_tensor = layer(out_tensor)\n",
    "                \n",
    "#         layer = nn.Linear(675, 512)\n",
    "#         out_tensor = layer(out_tensor)\n",
    "                \n",
    "#         layer = nn.ReLU()\n",
    "#         out_tensor = layer(out_tensor)\n",
    "                \n",
    "#         layer = nn.Dropout(0.3)\n",
    "#         out_tensor = layer(out_tensor)\n",
    "        \n",
    "#         layer = nn.ReLU()\n",
    "#         out_tensor = layer(out_tensor)\n",
    "        \n",
    "#         layer = nn.Linear(512, N_CLASSES)\n",
    "#         out_tensor = layer(out_tensor)\n",
    "        \n",
    "#         print(\"out_dimensions\", out_tensor.shape)\n",
    "        \n",
    "        output = model(x)\n",
    "        optimizer.zero_grad()\n",
    "        batch_loss = loss_fn(output, y)\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        loss += batch_loss.item()\n",
    "        accuracy += get_batch_accuracy(output, y, train_N)\n",
    "\n",
    "    print(\"Training Loss\", loss)\n",
    "    print(\"Training Accuracy\", accuracy)\n",
    "\n",
    "def validate():\n",
    "    loss = 0\n",
    "    accuracy = 0\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x, y in test_loader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            output = model(x)\n",
    "            loss += loss_fn(output, y).item()\n",
    "            accuracy += get_batch_accuracy(output, y, test_N)\n",
    "    \n",
    "    print(\"Testing Loss\", loss)\n",
    "    print(\"Testing Accuracy\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7258eb7",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<unknown>, line 2)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[36m(most recent call last)\u001b[39m:\n",
      "  File \u001b[92m~/.conda/envs/Senior_Design/lib/python3.12/site-packages/IPython/core/interactiveshell.py:3701\u001b[39m in \u001b[95mrun_code\u001b[39m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  Cell \u001b[92mIn[10]\u001b[39m\u001b[92m, line 1\u001b[39m\n    get_ipython().run_cell_magic('time', '', '\\nif os.path.isfile(\"checkpoint.tar\"):\\n    model, optimizer, epoch, loss = load_checkpoint(model, optimizer, \"checkpoint.tar\"):\\n\\nN_EPOCHS = 20\\nfor N in range(N_EPOCHS):\\n    print(f\"Epoch {epoch + 1}\")\\n    train()\\n    validate()\\n    print(\"\\\\n\")\\n')\n",
      "  File \u001b[92m~/.conda/envs/Senior_Design/lib/python3.12/site-packages/IPython/core/interactiveshell.py:2572\u001b[39m in \u001b[95mrun_cell_magic\u001b[39m\n    result = fn(*args, **kwargs)\n",
      "  File \u001b[92m~/.conda/envs/Senior_Design/lib/python3.12/site-packages/IPython/core/magics/execution.py:1356\u001b[39m in \u001b[95mtime\u001b[39m\n    expr_ast = self.shell.compile.ast_parse(expr)\n",
      "\u001b[36m  \u001b[39m\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/Senior_Design/lib/python3.12/site-packages/IPython/core/compilerop.py:86\u001b[39m\u001b[36m in \u001b[39m\u001b[35mast_parse\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mreturn compile(source, filename, symbol, self.flags | PyCF_ONLY_AST, 1)\u001b[39m\n",
      "  \u001b[36mFile \u001b[39m\u001b[32m<unknown>:2\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mmodel, optimizer, epoch, loss = load_checkpoint(model, optimizer, \"checkpoint.tar\"):\u001b[39m\n                                                                                       ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "if os.path.isfile(\"checkpoint.tar\"):\n",
    "    model, optimizer, epoch, loss = load_checkpoint(model, optimizer, \"checkpoint.tar\")\n",
    "\n",
    "N_EPOCHS = 20\n",
    "for N in range(N_EPOCHS):\n",
    "    print(f\"Epoch {epoch + 1}\")\n",
    "    train()\n",
    "    validate()\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a568828d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'save_checkpoint' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43msave_checkpoint\u001b[49m(model, optimizer, \u001b[32m19\u001b[39m, \u001b[32m20.49\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcheckpoint.tar\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'save_checkpoint' is not defined"
     ]
    }
   ],
   "source": [
    "save_checkpoint(model, optimizer, 19, 20.49, \"checkpoint.tar\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-Senior_Design]",
   "language": "python",
   "name": "conda-env-.conda-Senior_Design-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
