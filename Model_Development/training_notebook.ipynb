{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35251eb6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from PIL import Image\n",
    "\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40568d02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31b336f6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "IMG_H = 28\n",
    "IMG_W = 28\n",
    "IMG_C = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92d7f4c6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Transform to resize images\n",
    "motion_transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_H, IMG_W)),\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9fb76c07",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Custom Dataset class to read the data from the excel file and image directory\n",
    "class MotionDataset(Dataset):\n",
    "    def __init__(self, xlsx_file, image_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            xlsx_file (string): Path to the excel file with annotations.\n",
    "            image_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.data_info = pd.read_excel(xlsx_file)\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_info)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        img_name = os.path.join(self.image_dir,\n",
    "                                str(self.data_info.iloc[idx]['PrimaryImageFilename']))\n",
    "        image = Image.open(img_name).convert('RGB')\n",
    "\n",
    "        # 'PGC1' is the target label\n",
    "        label = self.data_info.iloc[idx]['PGC1']-1\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f350717e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "dataset = MotionDataset(xlsx_file='cleaned_product_list.xlsx', image_dir='/home/hice1/rlopez76/scratch/motion_dataset', transform=motion_transform)\n",
    "train_size = int(len(dataset) * 0.8)\n",
    "test_size = len(dataset) - train_size\n",
    "\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32) # need to look into other parameters\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)\n",
    "\n",
    "train_N = len(train_loader.dataset)\n",
    "test_N = len(test_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0fa73b69",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "N_CLASSES = 8\n",
    "KERNEL_SIZE = 3\n",
    "FLATTENED_IMG_SIZE = IMG_H * IMG_W * IMG_C\n",
    "\n",
    "model = nn.Sequential(\n",
    "        nn.Conv2d(in_channels=3, out_channels=25, kernel_size=3, stride=1, padding=1),\n",
    "        nn.BatchNorm2d(25),\n",
    "        nn.ReLU(),        \n",
    "        nn.MaxPool2d(2, stride = 2),\n",
    "        nn.Conv2d(in_channels=25, out_channels=50, kernel_size=3, stride=1, padding=1),\n",
    "        nn.BatchNorm2d(50),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.2),\n",
    "        nn.MaxPool2d(2, stride = 2),\n",
    "        nn.Conv2d(in_channels=50, out_channels=75, kernel_size=3, stride=1, padding=1),\n",
    "        nn.BatchNorm2d(75),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.2), \n",
    "        nn.MaxPool2d(2, stride = 2),\n",
    "        nn.Flatten(), \n",
    "        nn.Linear(675, 512),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.3),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(512, N_CLASSES)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2342f4c3",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "def save_checkpoint(model, optimizer, epoch, loss, save_path):\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': loss,\n",
    "    }, save_path)\n",
    "    \n",
    "def load_checkpoint(model, optimizer, load_path):\n",
    "    checkpoint = torch.load(load_path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    epoch = checkpoint['epoch']\n",
    "    loss = checkpoint['loss']\n",
    "    \n",
    "    return model, optimizer, epoch, loss\n",
    "\n",
    "def get_batch_accuracy(output, y, N):\n",
    "    pred = output.argmax(dim = 1, keepdim = True)\n",
    "    correct = pred.eq(y.view_as(pred)).sum().item()\n",
    "    acc = correct / N\n",
    "    return acc\n",
    "\n",
    "def train():\n",
    "    loss = 0\n",
    "    accuracy = 0\n",
    "\n",
    "    model.train()\n",
    "    for x, y in train_loader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "#         print(\"x shape\", x.shape)\n",
    "        \n",
    "#         firstx = x\n",
    "        \n",
    "#         layer = nn.Conv2d(in_channels=3, out_channels=25, kernel_size=3, stride=1, padding=1)\n",
    "#         out_tensor = layer(x)\n",
    "        \n",
    "#         layer = nn.BatchNorm2d(25)\n",
    "#         out_tensor = layer(out_tensor)\n",
    "        \n",
    "#         layer = nn.ReLU()        \n",
    "#         out_tensor = layer(out_tensor)\n",
    "                        \n",
    "#         layer = nn.MaxPool2d(2, stride = 2)\n",
    "#         out_tensor = layer(out_tensor)\n",
    "            \n",
    "#         layer = nn.Conv2d(in_channels=25, out_channels=50, kernel_size=3, stride=1, padding=1)\n",
    "#         out_tensor = layer(out_tensor)\n",
    "        \n",
    "#         layer = nn.BatchNorm2d(50)\n",
    "#         out_tensor = layer(out_tensor)\n",
    "            \n",
    "#         layer = nn.ReLU()    \n",
    "#         out_tensor = layer(out_tensor)\n",
    "        \n",
    "#         layer = nn.Dropout(0.2)\n",
    "#         out_tensor = layer(out_tensor)\n",
    "        \n",
    "#         layer = nn.MaxPool2d(2, stride = 2)\n",
    "#         out_tensor = layer(out_tensor)        \n",
    "        \n",
    "#         layer = nn.Conv2d(in_channels=50, out_channels=75, kernel_size=3, stride=1, padding=1)\n",
    "#         out_tensor = layer(out_tensor)\n",
    "        \n",
    "#         layer = nn.BatchNorm2d(75)\n",
    "#         out_tensor = layer(out_tensor)\n",
    "            \n",
    "#         layer = nn.ReLU()\n",
    "#         out_tensor = layer(out_tensor)\n",
    "            \n",
    "#         layer = nn.Dropout(0.2)    \n",
    "#         out_tensor = layer(out_tensor)\n",
    "                \n",
    "#         layer = nn.MaxPool2d(2, stride = 2)\n",
    "#         out_tensor = layer(out_tensor)\n",
    "        \n",
    "#         layer = nn.Flatten()        \n",
    "#         out_tensor = layer(out_tensor)\n",
    "                \n",
    "#         layer = nn.Linear(675, 512)\n",
    "#         out_tensor = layer(out_tensor)\n",
    "                \n",
    "#         layer = nn.ReLU()\n",
    "#         out_tensor = layer(out_tensor)\n",
    "                \n",
    "#         layer = nn.Dropout(0.3)\n",
    "#         out_tensor = layer(out_tensor)\n",
    "        \n",
    "#         layer = nn.ReLU()\n",
    "#         out_tensor = layer(out_tensor)\n",
    "        \n",
    "#         layer = nn.Linear(512, N_CLASSES)\n",
    "#         out_tensor = layer(out_tensor)\n",
    "        \n",
    "#         print(\"out_dimensions\", out_tensor.shape)\n",
    "        \n",
    "        output = model(x)\n",
    "        optimizer.zero_grad()\n",
    "        batch_loss = loss_fn(output, y)\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        loss += batch_loss.item()\n",
    "        accuracy += get_batch_accuracy(output, y, train_N)\n",
    "\n",
    "    print(\"Training Loss\", loss)\n",
    "    print(\"Training Accuracy\", accuracy)\n",
    "\n",
    "def validate():\n",
    "    loss = 0\n",
    "    accuracy = 0\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x, y in test_loader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            output = model(x)\n",
    "            loss += loss_fn(output, y).item()\n",
    "            accuracy += get_batch_accuracy(output, y, test_N)\n",
    "    \n",
    "    print(\"Testing Loss\", loss)\n",
    "    print(\"Testing Accuracy\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7258eb7",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20\n",
      "Training Loss 35.183555433526635\n",
      "Training Accuracy 0.940501043841336\n",
      "Testing Loss 7.879574125632644\n",
      "Testing Accuracy 0.9526791927627003\n",
      "\n",
      "\n",
      "Epoch 20\n",
      "Training Loss 24.957764111924917\n",
      "Training Accuracy 0.9577244258872643\n",
      "Testing Loss 9.632865861058235\n",
      "Testing Accuracy 0.9318023660403618\n",
      "\n",
      "\n",
      "Epoch 20\n",
      "Training Loss 19.64739220123738\n",
      "Training Accuracy 0.9672929714683361\n",
      "Testing Loss 8.402048360556364\n",
      "Testing Accuracy 0.9498956158663884\n",
      "\n",
      "\n",
      "Epoch 20\n",
      "Training Loss 17.11409496096894\n",
      "Training Accuracy 0.9712943632567852\n",
      "Testing Loss 9.624446269124746\n",
      "Testing Accuracy 0.940153096729297\n",
      "\n",
      "\n",
      "Epoch 20\n",
      "Training Loss 15.575661132577807\n",
      "Training Accuracy 0.9712943632567845\n",
      "Testing Loss 18.21726930886507\n",
      "Testing Accuracy 0.8803061934585943\n",
      "\n",
      "\n",
      "Epoch 20\n",
      "Training Loss 15.656229888903908\n",
      "Training Accuracy 0.9719902574808628\n",
      "Testing Loss 12.337572522461414\n",
      "Testing Accuracy 0.9116214335421015\n",
      "\n",
      "\n",
      "Epoch 20\n",
      "Training Loss 14.250629106303677\n",
      "Training Accuracy 0.9751217814892136\n",
      "Testing Loss 10.203531759791076\n",
      "Testing Accuracy 0.934585942936674\n",
      "\n",
      "\n",
      "Epoch 20\n",
      "Training Loss 13.550350398290902\n",
      "Training Accuracy 0.9747738343771742\n",
      "Testing Loss 10.263515600934625\n",
      "Testing Accuracy 0.9359777313848295\n",
      "\n",
      "\n",
      "Epoch 20\n",
      "Training Loss 11.79943827475654\n",
      "Training Accuracy 0.9766875434933886\n",
      "Testing Loss 14.074589993804693\n",
      "Testing Accuracy 0.9220598469032706\n",
      "\n",
      "\n",
      "Epoch 20\n",
      "Training Loss 11.28794512397144\n",
      "Training Accuracy 0.9792971468336806\n",
      "Testing Loss 15.22797778248787\n",
      "Testing Accuracy 0.9164926931106473\n",
      "\n",
      "\n",
      "Epoch 20\n",
      "Training Loss 10.948749763076194\n",
      "Training Accuracy 0.9796450939457196\n",
      "Testing Loss 11.084626889787614\n",
      "Testing Accuracy 0.9324982602644398\n",
      "\n",
      "\n",
      "Epoch 20\n",
      "Training Loss 9.253653849824332\n",
      "Training Accuracy 0.983646485734168\n",
      "Testing Loss 12.559828227385879\n",
      "Testing Accuracy 0.9276270006958942\n",
      "\n",
      "\n",
      "Epoch 20\n",
      "Training Loss 10.525182479061186\n",
      "Training Accuracy 0.9812108559498951\n",
      "Testing Loss 12.156167103908956\n",
      "Testing Accuracy 0.9318023660403619\n",
      "\n",
      "\n",
      "Epoch 20\n",
      "Training Loss 9.48580412339652\n",
      "Training Accuracy 0.9819067501739731\n",
      "Testing Loss 15.85785660147667\n",
      "Testing Accuracy 0.897007654836465\n",
      "\n",
      "\n",
      "Epoch 20\n",
      "Training Loss 10.760822020063642\n",
      "Training Accuracy 0.978949199721642\n",
      "Testing Loss 13.827346134930849\n",
      "Testing Accuracy 0.9144050104384137\n",
      "\n",
      "\n",
      "Epoch 20\n",
      "Training Loss 9.014381360233529\n",
      "Training Accuracy 0.9836464857341679\n",
      "Testing Loss 13.025305174291134\n",
      "Testing Accuracy 0.9206680584551148\n",
      "\n",
      "\n",
      "Epoch 20\n",
      "Training Loss 8.732484019943513\n",
      "Training Accuracy 0.9852122477383433\n",
      "Testing Loss 14.42421883251518\n",
      "Testing Accuracy 0.9220598469032708\n",
      "\n",
      "\n",
      "Epoch 20\n",
      "Training Loss 8.836072253761813\n",
      "Training Accuracy 0.9834725121781481\n",
      "Testing Loss 13.19513776153326\n",
      "Testing Accuracy 0.9227557411273487\n",
      "\n",
      "\n",
      "Epoch 20\n",
      "Training Loss 11.509719226800371\n",
      "Training Accuracy 0.9768615170494084\n",
      "Testing Loss 13.841343140229583\n",
      "Testing Accuracy 0.9192762700069588\n",
      "\n",
      "\n",
      "Epoch 20\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "if os.path.isfile(\"checkpoint.tar\"):\n",
    "    model, optimizer, epoch, loss = load_checkpoint(model, optimizer, \"checkpoint.tar\")\n",
    "\n",
    "N_EPOCHS = 20\n",
    "for N in range(N_EPOCHS):\n",
    "    print(f\"Epoch {epoch + 1}\")\n",
    "    train()\n",
    "    validate()\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a568828d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'save_checkpoint' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43msave_checkpoint\u001b[49m(model, optimizer, \u001b[32m19\u001b[39m, \u001b[32m20.49\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcheckpoint.tar\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'save_checkpoint' is not defined"
     ]
    }
   ],
   "source": [
    "save_checkpoint(model, optimizer, 19, 20.49, \"checkpoint.tar\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-Senior_Design]",
   "language": "python",
   "name": "conda-env-.conda-Senior_Design-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
